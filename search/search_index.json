{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>SeaSearch is a lightweight search engine built on open source search engine (ZincSearch), implemented in Go language. Our goal is to use SeaSearch to replace ElasticSearch as the default search engine for Seafile.</p>"},{"location":"#seasearch-vs-elasticsearch","title":"SeaSearch vs. ElasticSearch:","text":"<ul> <li>Lightweight: SeaSearch is implemented in Go language. So it's more lightweight than ElasticSearch, which is implemented in Java.</li> <li>One Index per Library: SeaSearch can support large number of indexes in the system. With this feature, we can create one index for each library in Seafile. This limits the amount of data that needs to be searched for queries. With ElasticSearch, we have to save data from all libraries into one index, which is not good for performance when you have large amount of data.</li> <li>Good Compatibility: API compatible with ElasticSearch</li> <li>Support S3 Storage: SeaSearch can use S3 as storage</li> <li>Shared Storage Architecture for Cluster: ElasticSearch's cluster architecture is based on replication of data among nodes. It's complex to maintain and not easy to scale. SeaSearch uses a shared-storage architecture. Cluster nodes share the same storage (usually S3 compatible object storage). With this architecture, it's easier to provide HA guarantees and easier to maintain. It's also possible to scale query performance by using more query nodes.</li> </ul>"},{"location":"#project-status-and-plan","title":"Project Status and Plan","text":"<p>At the moment (end of 2024) the text indexing and search feature is ready for Beta usage. Upcoming features includes:</p> <ul> <li>Clustering</li> <li>Vector indexing and search</li> </ul>"},{"location":"api/seasearch_api/","title":"API introduction","text":"<p>SeaSearch uses Http Basic Auth for permission verification, and the API request needs to carry the corresponding token in the header.</p> <pre><code># headers\n{\n  'Authorization': 'Basic &lt;basic auth token&gt;'\n}\n</code></pre>"},{"location":"api/seasearch_api/#user-management","title":"User management","text":""},{"location":"api/seasearch_api/#administrator-user","title":"Administrator user","text":"<p>SeaSearch manages API permissions through accounts. When the program is started for the first time, an administrator account needs to be configured through environment variables.</p> <p>The following is an example of an administrator account:</p> <pre><code>set ZINC_FIRST_ADMIN_USER=admin\nset ZINC_FIRST_ADMIN_PASSWORD=xxx\n</code></pre>"},{"location":"api/seasearch_api/#normal-user","title":"Normal user","text":"<p>Users can be created/updated via the API:</p> <pre><code>[POST] /api/user\n\n{ \n    \"_id\": \"prabhat\",\n    \"name\": \"Prabhat Sharma\",\n    \"role\": \"admin\", // or user\n    \"password\": \"xxx\"\n}\n</code></pre> <p>get all users\uff1a</p> <pre><code>[GET] /api/user\n</code></pre> <p>delete user\uff1a</p> <pre><code>[DELETE] /api/user/${userId}\n</code></pre>"},{"location":"api/seasearch_api/#index-related","title":"Index related","text":""},{"location":"api/seasearch_api/#create-index","title":"create index","text":"<p>Create a SeaSearch index, and you can set both mappings and settings at the same time.</p> <p>We can also set settings or mapping directly through other requests. If the index does not exist, it will be created automatically.</p> <p>SeaSearch documentation\uff1ahttps://zincsearch-docs.zinc.dev/api/index/create/#update-a-exists-index</p> <p>ES documentation\uff1ahttps://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html</p>"},{"location":"api/seasearch_api/#configure-mappings","title":"Configure mappings","text":"<p>Mappings define the rules for fields in a document, such as type, format, etc.</p> <p>Mapping can be configured via a separate API:</p> <p>SeaSearch api: https://zincsearch-docs.zinc.dev/api-es-compatible/index/update-mapping/</p> <p>ES related instructions\uff1ahttps://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html</p>"},{"location":"api/seasearch_api/#configure-settings","title":"Configure settings","text":"<p>Settings set the analyzer sharding and other related settings of the index.</p> <p>SeaSearch api: https://zincsearch-docs.zinc.dev/api-es-compatible/index/update-settings/</p> <p>ES related instructions\uff1a</p> <ul> <li> <p>analyzer related concepts\uff1ahttps://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-concepts.html</p> </li> <li> <p>How to specify an analyzer\uff1ahttps://www.elastic.co/guide/en/elasticsearch/reference/current/specify-analyzer.html</p> </li> </ul>"},{"location":"api/seasearch_api/#analyzer-support","title":"Analyzer support","text":"<p>Analyzer can configure the default when creating an index, or set it for a specific field. (Refer to the settings ES documentation in the previous section to understand the relevant concepts.)</p> <p>The analyzers supported by SeaSearch can be found on this page: https://zincsearch-docs.zinc.dev/api/index/analyze/. The concepts such as tokenize and token filter are consistent with ES, and most of the commonly used analyzers and tokenizers in ES are supported.</p> <p>Supported general analyzers</p> <ul> <li> <p>standard, the default analyzer. If not specified, this analyzer is used to split words and lowercase them.</p> </li> <li> <p>simple, split according to non-letters (symbols are filtered), lowercase</p> </li> <li> <p>keyword, no word segmentation, directly treat input as output</p> </li> <li> <p>stop, lowercase, stop word filter (the, a, is, etc.)</p> </li> <li> <p>web, implemented by Bluge, matching email addresses, urls, etc. Handling lowercase, using stop word filters</p> </li> <li> <p>regexp/pattern, regular expression, default is \\W+ (non-character segmentation), supports lowercase and stop words</p> </li> <li> <p>whitespace, split by space, do not convert to lowercase</p> </li> </ul>"},{"location":"api/seasearch_api/#luanguages-analyzers","title":"Luanguages analyzers","text":"Country Shortened form arabic ar Asia Countries cjk sorani ckb danish da german de english en spanish es persian fa finnish fi french fr hindi hi hungarian hu italian it dutch nl norwegian no portuguese pt romanian ro russian ru swedish sv turkish tr <p>Chinese analyzer:</p> <ul> <li> <p>gse_standard, use the shortest path algorithm to segment words</p> </li> <li> <p>gse_search, the search engine's word segmentation mode provides as many keywords as possible</p> </li> </ul> <p>The Chinese analyzer uses the gse library to implement word segmentation. It is a Golang implementation of the Python stammer library. It is not enabled by default and needs to be enabled through environment variables.</p> <pre><code>ZINC_PLUGIN_GSE_ENABLE=true\n# true: enable Chinese word segmentation support, default is false\n\nZINC_PLUGIN_GSE_DICT_EMBED=BIG \n# BIG: use the gse built-in vocabulary and stop words; otherwise, use the SeaSearch built-in simple vocabulary, the default is small\n\nZINC_PLUGIN_GSE_ENABLE_STOP=true\n# true: use stop words, default true\n\nZINC_PLUGIN_GSE_ENABLE_HMM=true\n# Use HMM mode for search word segmentation, default is true\n\nZINC_PLUGIN_GSE_DICT_PATH=./plugins/gse/dict\n# To use a user-defined word library and stop words, you need to put the content in the configured path, and name the word library user.txt and the stop words stop.txt\n</code></pre>"},{"location":"api/seasearch_api/#full-text-search","title":"Full text search","text":""},{"location":"api/seasearch_api/#document-crud","title":"document CRUD","text":"<p>create document:</p> <p>SeaSearch API: https://zincsearch-docs.zinc.dev/api-es-compatible/document/create/</p> <p>ES API\uff1ahttps://www.elastic.co/guide/en/elasticsearch/reference/current/docs-index_.html</p> <p>update document:</p> <p>SeaSearch API: https://zincsearch-docs.zinc.dev/api-es-compatible/document/update/</p> <p>ES API: https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-update.html</p> <p>delete document\uff1a</p> <p>SeaSearch API: https://zincsearch-docs.zinc.dev/api-es-compatible/document/delete/</p> <p>ES API: https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-delete.html</p> <p>Get document by id:</p> <pre><code>[GET] /api/${indexName}/_doc/${docId}\n</code></pre>"},{"location":"api/seasearch_api/#batch-operation","title":"Batch Operation","text":"<p>Batch operations should be used to update indexes whenever possible.</p> <p>SeaSearch API\uff1a https://zincsearch-docs.zinc.dev/api-es-compatible/document/bulk/#request</p> <p>ES API\uff1ahttps://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html</p>"},{"location":"api/seasearch_api/#search","title":"search","text":"<p>API examples:</p> <p>https://zincsearch-docs.zinc.dev/api-es-compatible/search/search/</p> <p>Full-text search uses DSL. For usage, please refer to:</p> <p>https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html</p> <p>delete-by-query\uff1aDelete based on query</p> <pre><code>[POST] /es/${indexName}/_delete_by_query\n\n{\n  \"query\": {\n    \"match\": {\n      \"name\": \"jack\"\n    }\n  }\n}\n</code></pre> <p>ES API: https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-delete-by-query.html</p> <p>multi-search\uff0csupports executing different queries on different indexes:</p> <p>SeaSearch API: https://zincsearch-docs.zinc.dev/api-es-compatible/search/msearch/</p> <p>ES API: https://www.elastic.co/guide/en/elasticsearch/reference/current/search-multi-search.html</p> <p>We have extended multi-search to support using the same statistics when searching different indexes to make the score calculation more accurate. You can enable it by setting query: unify_score=true in the request.</p> <pre><code>[POST] /es/_msearch?unify_score=true\n\n{\"index\": \"t1\"}\n{\"query\": {\"bool\": {\"should\": [{\"match\": {\"filename\": {\"query\": \"test string\", \"minimum_should_match\": \"-25%\"}}}, {\"match\": {\"filename.ngram\": {\"query\": \"test string\", \"minimum_should_match\": \"80%\"}}}], \"minimum_should_match\": 1}}, \"from\": 0, \"size\": 10, \"_source\": [\"path\", \"repo_id\", \"filename\", \"is_dir\"], \"sort\": [\"_score\"]}\n{\"index\": \"t2\"}\n{\"query\": {\"bool\": {\"should\": [{\"match\": {\"filename\": {\"query\": \"test string\", \"minimum_should_match\": \"-25%\"}}}, {\"match\": {\"filename.ngram\": {\"query\": \"test string\", \"minimum_should_match\": \"80%\"}}}], \"minimum_should_match\": 1}}, \"from\": 0, \"size\": 10, \"_source\": [\"path\", \"repo_id\", \"filename\", \"is_dir\"], \"sort\": [\"_score\"]}\n</code></pre>"},{"location":"api/seasearch_api/#vector-search","title":"Vector search","text":"<p>We have developed a vector search function for the SeaSearch extension. The following is an introduction to the relevant API.</p>"},{"location":"api/seasearch_api/#create-vector-search","title":"Create vector search","text":"<p>To use the vector search function, you need to create a vector index in advance, which can be done through mapping.</p> <p>We create an index and set the vector field of the document data to be written to be called \"vec\", the index type is flat, and the vector dimension is 768</p> <pre><code>[PUT] /es/${indexName}/_mapping\n\n{\n\"properties\":{\n        \"vec\":{\n            \"type\":\"vector\", \n            \"dims\":768,\n            \"m\":64,\n            \"nbits\":8,\n            \"vec_index_type\":\"flat\"\n        }\n    }\n}\n</code></pre> <p>Parameter Description:</p> <pre><code>${indexName} zincIndex, index name\n\ntype,  fixed to vector, indicating vector index\ndims,  vector dimensions\nm,     ivf_pq index required parameters, need to be divisible by dims\nnbits, ivf_pq index required parameter, default is 8\nvec_index_type, index type, supports two types: flat and ivf_pq\n</code></pre>"},{"location":"api/seasearch_api/#write-a-document-containing-a-vector","title":"Write a document containing a vector","text":"<p>There is no difference between writing a document containing a vector and writing a normal document at the API level. You can choose the appropriate method.</p> <p>The following takes the bluk API as an example</p> <pre><code>[POST] /es/_bulk\n\nbody:\n\n{ \"index\" : { \"_index\" : \"index1\" } } \n{\"name\": \"jack1\",\"vec\":[10.2,10.41,9.5,22.2]}\n{ \"index\" : { \"_index\" : \"index1\" } } \n{\"name\": \"jack2\",\"vec\":[10.2,11.41,9.5,22.2]}\n{ \"index\" : { \"_index\" : \"index1\" } } \n{\"name\": \"jack3\",\"vec\":[10.2,12.41,9.5,22.2]}\n</code></pre> <p>Note that the _bulk API strictly requires the format of each line, and the data cannot exceed one line. For details, please refer to ES bulk</p> <p>Modification and deletion can also be done using bulk. After deleting a document, its corresponding vector data will also be deleted</p>"},{"location":"api/seasearch_api/#retrieval-vector","title":"Retrieval vector","text":"<p>By passing in a vector, we can search for N similar vectors in the system and return the corresponding document information:</p> <pre><code>[POST] /api/${indexName}/_search/vector\n\nbody:\n{\n    {\n    \"query_field\":\"vec\",\n    \"k\":7,\n    \"return_fields\":[\"name\"],\n    \"vector\":[10.2,10.40,9.5,22.2.......],\n    \"_source\":false\n    }\n}\n</code></pre> <p>The API response format is the same as the full-text search format.</p> <p>The following is a description of the parameters:</p> <pre><code>${indexName} zincIndex, index name\n\nquery_field,    the field in the index to retrieve, the field must be of vector type\nk,              the number of K most similar vectors to return\nreturn_fields,  the name of the field to be returned individually\nvector,         the vector used for query\nnprobe,         only works for ivf_pq index type, the number of clusters to query, the higher the number, the more accurate\n_source,        it is used to control whether to return the _source field, supports bool or an array, describing which fields need to be returned\n</code></pre>"},{"location":"api/seasearch_api/#rebuild-index","title":"Rebuild index","text":"<p>Rebuild the index immediately, suitable for situations where you don't need to wait for background automatic detection.</p> <pre><code>[POST] /api/:target/:field/_rebuild\n</code></pre>"},{"location":"api/seasearch_api/#query-recall","title":"query recall","text":"<p>For vectors of type ivf_pq, recall checks can be performed on their data.</p> <pre><code>[POST] /api/:target/_recall\n{\n    \"field\":\"vec_001\", # Fields to test\n    \"k\":10, \n    \"nprobe\":5, # nprobe number\n    \"query_count\":1000 # Number of times the test was performed\n}\n</code></pre>"},{"location":"api/seasearch_api/#vector-search-usage-examples","title":"Vector search usage examples","text":"<p>Next, we will demonstrate how to index a batch of papers. Each paper may contain multiple vectors that need to be indexed. We hope to obtain the most similar N vectors through vector retrieval, and thus obtain their corresponding paper-ids.</p>"},{"location":"api/seasearch_api/#creating-seasearch-indexes-and-vector-indexes","title":"Creating SeaSearch indexes and vector indexes","text":"<p>The first step is to set the mapping of the vector index. When setting the mapping, the index and vector index are automatically created.</p> <p>Since paper-id is just a normal string, we don't need to analyze it, so we set its type to keyword:</p> <pre><code>[PUT] /es/paper/_mapping\n\n{\n\"properties\":{\n        \"title-vec\":{\n            \"type\":\"vector\", \n            \"dims\":768,\n            \"vec_index_type\":\"flat\",\n            \"m\":1\n        },\n        \"paper-id\":{\n            \"type\":\"keyword\"\n        }\n    }\n}\n</code></pre> <p>Through the above request, we created an index named paper and established a flat vector index for the title-vec field of the index.</p>"},{"location":"api/seasearch_api/#index-data","title":"Index data","text":"<p>We write these paper data to SeaSearch in batches through the _bulk API.</p> <pre><code>[POST] /es/_bulk\n\n{ \"index\" : {\"_index\" : \"paper\" } } \n{\"paper-id\": \"001\",\"title-vec\":[10.2,10.40,9.5,22.2....]}\n{ \"index\" : {\"_index\" : \"paper\" } } \n{\"paper-id\": \"002\",\"title-vec\":[10.2,11.40,9.5,22.2....]}\n{ \"index\" : {\"_index\" : \"paper\" } } \n{\"paper-id\": \"003\",\"title-vec\":[10.2,12.40,9.5,22.2....]}\n....\n</code></pre>"},{"location":"api/seasearch_api/#retrieving-data","title":"Retrieving data","text":"<p>Now we can retrieve it using the vector:</p> <pre><code>[POST] /api/paper/_search/vector\n\n{\n    \"query_field\":\"title-vec\",\n    \"k\":10,\n    \"return_fields\":[\"paper-id\"],\n    \"vector\":[10.2,10.40,9.5,22.2....]\n}\n</code></pre> <p>The document corresponding to the most similar vector can be retrieved, and the paper-id can be obtained. Since a paper may contain multiple vectors, if multiple vectors of a paper are very similar to the query vector, then this paper-id may appear multiple times in the results.</p>"},{"location":"api/seasearch_api/#maintaining-vector-data","title":"Maintaining vector data","text":""},{"location":"api/seasearch_api/#update-the-document-directly","title":"Update the document directly","text":"<p>After a document is successfully imported, SeaSearch will return its doc id. We can directly update a document based on the doc id:</p> <pre><code>[POST] /es/_bulk\n\n{ \"update\" : {\"_id\":\"23gZX9eT6QM\",\"_index\" : \"paper\" } } \n{\"paper-id\": \"005\",\"vec\":[10.2,1.43,9.5,22.2...]}\n</code></pre>"},{"location":"api/seasearch_api/#query-first-and-then-update","title":"Query first and then update","text":"<p>If the returned doc id is not saved, you can first use SeaSearch's full-text search function to query the documents corresponding to paper-id:</p> <pre><code>[POST] /es/paper/_search\n\n{\n    \"query\": {\n        \"bool\": {\n            \"must\": [\n                {\n                    \"term\": {\"paper-id\":\"003\"}\n                }\n            ]\n        }\n    }\n}\n</code></pre> <p>Through DSL, we can directly retrieve the document corresponding to the paper-id and its doc id.</p>"},{"location":"api/seasearch_api/#fully-updated-paper","title":"Fully updated paper","text":"<p>A paper contains multiple vectors. If a vector needs to be updated, we can directly update the document corresponding to the vector. However, in actual applications, it is not easy to distinguish which contents of a paper are newly added and which are updated.</p> <p>We can adopt the method of full update:</p> <ul> <li> <p>First, query all documents of a paper through DSL</p> </li> <li> <p>Delete all documents</p> </li> <li> <p>Import the latest paper data</p> </li> </ul> <p>Steps 2 and 3 can be performed in one batch operation.</p> <p>The following example will demonstrate deleting the document of paper 001 and re-importing it; at the same time, directly updating paper 005 and paper 006 because they only have one vector:</p> <pre><code>[POST] /es/_bulk\n\n\n{ \"index\" : {\"_index\" : \"paper\" } } \n{\"paper-id\": \"001\",\"title-vec\":[10.2,10.40,9.5,22.2....]}\n{ \"index\" : {\"_index\" : \"paper\" } } \n{\"paper-id\": \"002\",\"title-vec\":[10.2,11.40,9.5,22.2....]}\n{ \"index\" : {\"_index\" : \"paper\" } } \n{\"paper-id\": \"003\",\"title-vec\":[10.2,12.40,9.5,22.2....]}\n....\n</code></pre>"},{"location":"config/","title":"SeaSearch Configuration","text":""},{"location":"config/#single-node-configurations","title":"Single-Node Configurations","text":""},{"location":"config/#basic-configurations","title":"Basic Configurations","text":"<pre><code># log mode of gin framework\uff0cdefault release\nZINC_WAL_ENABLE=true\n\n# type of storage's engine, i.e., s3\nZINC_STORAGE_TYPE=\n\n# the number of shards, since seaseach has one index per database, in order to improve loading efficiency, the default value is changed to 1\nZINC_SHARD_NUM=1\n</code></pre>"},{"location":"config/#s3-storage-configurations","title":"S3 Storage Configurations","text":"<p>To enable s3 storage configurations, the term <code>ZINC_STORAGE_TYPE</code> has to be set as <code>ZINC_STORAGE_TYPE=s3</code>.</p> <pre><code># the maximum local cache file size\nZINC_MAX_OBJ_CACHE_SIZE=\n\n# S3 relative informations\nZINC_S3_ACCESS_ID=&lt;your s3 access id&gt;\nZINC_S3_USE_V4_SIGNATURE=&lt;your s3 signature&gt;\nZINC_S3_ACCESS_SECRET=&lt;your s3 access secret&gt;\nZINC_S3_ENDPOINT=&lt;your s3 endpoint&gt;\nZINC_S3_USE_HTTPS=&lt;your s3 tls enabled&gt;\nZINC_S3_PATH_STYLE_REQUEST=&lt;your s3 style request path&gt;\nZINC_S3_AWS_REGION=&lt;your s3 AWS region&gt;\n</code></pre>"},{"location":"config/#logs-configurations","title":"Logs Configurations","text":"<pre><code>ZINC_LOG_OUTPUT=true #whether to output logs to files, default yes\nZINC_LOG_DIR=/opt/seasearch/data/log #log directory\nZINC_LOG_LEVEL=debug #log level\uff0cdefault debug\n</code></pre>"},{"location":"deploy/","title":"Deploy","text":""},{"location":"deploy/#download-the-seasearchyml","title":"Download the seasearch.yml","text":"<pre><code>wget https://haiwen.github.io/seasearch-docs/repo/seasearch.yml\n</code></pre>"},{"location":"deploy/#modify-env-file","title":"Modify .env file","text":"<p>First, you need to specify the environment variables used by the SeaSearch image in the relevant <code>.env</code> file. Some environment variables can be found in here. Please add and modify the environment variables (i.e., <code>&lt;...&gt;</code>) \u200b\u200bof the following fields in the <code>.env</code> file.</p> <pre><code># other environment variables in .env file\n# For Apple's chip (M2, e.g.), you should use the images with -nomkl tags (i.e., seafileltd/seasearch-nomkl:latest)\nSEASEARCH_IMAGE=seafileltd/seasearch:latest\n\nSEASEARCH_DATA_PATH=&lt;persistent-volume-path-of-seasearch&gt;\nZINC_FIRST_ADMIN_USER=&lt;admin-username&gt;  \nZINC_FIRST_ADMIN_PASSWORD=&lt;admin-password&gt;\n</code></pre>"},{"location":"deploy/#restart-the-service","title":"Restart the Service","text":"<pre><code>docker-compose down\ndocker-compose up\n</code></pre> <p>Browse seasearch services in http://127.0.0.1:4080/.</p>"}]}